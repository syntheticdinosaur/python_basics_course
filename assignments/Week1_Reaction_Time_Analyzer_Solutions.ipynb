{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§  Week 1 â€“ Reaction Time Analyzer (Solution)\n",
        "\n",
        "This notebook contains the **full instructor version** of the Week 1 seminar assignment. It demonstrates how to perform simple data analysis and sanity checks on simulated **reaction time (RT)** data.\n",
        "\n",
        "In behavioral and cognitive neuroscience, reaction times are one of the most basic measurements of performance. Before interpreting such data, itâ€™s crucial to perform some *data sanity checks*: identify outliers, compute summary statistics, and verify plausibility. This notebook shows how to do this step by step using Python basics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Expected Output Example\n",
        "```\n",
        "Trials analyzed: 11\n",
        "Mean RT: 305.0 ms\n",
        "Median RT: 290 ms\n",
        "Fastest RT: 250 ms\n",
        "Slowest RT: 500 ms\n",
        "Performance: Average\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 â€“ Define the Data\n",
        "In an experiment, each trial records a *reaction time* â€” how long the participant takes to respond to a stimulus. These values are collected in a list.\n",
        "\n",
        "Real datasets can contain hundreds of trials, but here we only take **12** for clarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reaction_times = [250, 310, 295, 280, 275, 305, 290, 265, 300, 1080, 285, 500]\n",
        "print('Reaction times:', reaction_times)\n",
        "\n",
        "# uncomment the line below to check of your code runs on the full data for Bonus 1\n",
        "# reaction_times = full_reaction_times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 â€“ Count the Trials\n",
        "Before analyzing, always check how many trials were recorded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_trials = len(reaction_times)\n",
        "print('Number of trials:', num_trials)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3 â€“ Summary Statistics: Describe the Data\n",
        "We first compute **mean** and **median** reaction times to describe the dataset.\n",
        "\n",
        "Mathematically:\n",
        "\n",
        "$$\n",
        "\\text{mean} = \\frac{1}{N}\\sum_{i=1}^{N} RT_i, \\quad\n",
        "\\text{median} =\n",
        "\\begin{cases}\n",
        "RT_{\\frac{N+1}{2}}, & N \\text{ odd} \\\\\n",
        "\\frac{RT_{\\frac{N}{2}} + RT_{\\frac{N}{2}+1}}{2}, & N \\text{ even}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The **mean** is simply the average reaction time across all trials, while the **median** is the middle value â€” *but only after the data have been sorted in ascending order.*  \n",
        "Sorting ensures that smaller reaction times come first, so we can correctly identify the middle point.\n",
        "\n",
        "Weâ€™ll now implement these calculations manually, this helps you understand how these operations actually work internally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ’¡ Note on Median Indexing\n",
        "In mathematical formulas, list positions start at **1**, e.g. $RT_1$ is the first element.\n",
        "\n",
        "In **Python**, indices start at **0**, so we must shift every index by one:\n",
        "\n",
        "$$RT_{\\frac{N+1}{2}} (math) \\Rightarrow RT_{\\frac{N+1}{2}-1} = RT_{\\frac{N-1}{2}} (Python)$$\n",
        "\n",
        "Thus, we simply **subtract one after applying the formula** to get the correct element. Since division creates a decimal value, we wrap the result in `int()` to convert it into an integer index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort the data first\n",
        "sorted_rts = sorted(reaction_times)\n",
        "\n",
        "# Compute the sum manually (without using sum())\n",
        "sum_rt = 0\n",
        "for rt in reaction_times:\n",
        "    sum_rt += rt\n",
        "\n",
        "# Compute mean manually\n",
        "mean_rt = sum_rt / len(reaction_times)\n",
        "\n",
        "# Compute median manually\n",
        "n = len(sorted_rts)\n",
        "if n % 2 == 1:\n",
        "    median_rt = sorted_rts[int((n - 1) / 2)]\n",
        "else:\n",
        "    median_rt = (sorted_rts[int(n / 2 - 1)] + sorted_rts[int(n / 2)]) / 2\n",
        "\n",
        "print('Sorted RTs:', sorted_rts)\n",
        "print('Mean RT:', round(mean_rt, 1), 'ms')\n",
        "print('Median RT:', median_rt, 'ms')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4 â€“ Fastest and Slowest Trial\n",
        "We now scan through the list to find the **fastest** and **slowest** trials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fastest = reaction_times[0]\n",
        "slowest = reaction_times[0]\n",
        "for rt in reaction_times:\n",
        "    if rt < fastest:\n",
        "        fastest = rt\n",
        "    if rt > slowest:\n",
        "        slowest = rt\n",
        "\n",
        "print('Fastest RT:', fastest, 'ms')\n",
        "print('Slowest RT:', slowest, 'ms')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5 â€“ Remove Implausible Trials (Outliers)\n",
        "Some reaction times are implausible â€” **too short** (<150 ms) or **too long** (>1000 ms). These are considered *outliers*.\n",
        "\n",
        "There are two possible ways to handle them:\n",
        "1. **Create a new list** containing only valid reaction times (recommended for clarity).\n",
        "2. **Remove invalid values directly** using `.pop()`, but loop backwards to avoid shifting indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1 â€“ create a new list\n",
        "cleaned_rts = []\n",
        "for rt in reaction_times:\n",
        "    if 150 <= rt <= 1000:\n",
        "        cleaned_rts.append(rt)\n",
        "print('Cleaned RTs (new list):', cleaned_rts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 2 â€“ pop elements (loop backwards)\n",
        "reaction_times_pop = [250, 310, 295, 280, 275, 305, 290, 265, 300, 1080, 285, 500]\n",
        "for i in range(len(reaction_times_pop)-1, -1, -1):\n",
        "    if reaction_times_pop[i] < 150 or reaction_times_pop[i] > 1000:\n",
        "        reaction_times_pop.pop(i)\n",
        "print('Cleaned RTs (pop method):', reaction_times_pop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the data are cleaned, **copy your code from Step 3** (for mean and median) and run it again using `cleaned_rts`. This shows how cleaning affects the summary statistics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6 â€“ Recalculate Summary Statistics (After Cleaning)\n",
        "Letâ€™s repeat the same computations from step 3 with the cleaned data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_cleaned = sorted(cleaned_rts)\n",
        "sum_cleaned = 0\n",
        "for rt in cleaned_rts:\n",
        "    sum_cleaned += rt\n",
        "mean_cleaned = sum_cleaned / len(cleaned_rts)\n",
        "\n",
        "n = len(sorted_cleaned)\n",
        "if n % 2 == 1:\n",
        "    median_cleaned = sorted_cleaned[int((n - 1) / 2)]\n",
        "else:\n",
        "    median_cleaned = (sorted_cleaned[int(n / 2 - 1)] + sorted_cleaned[int(n / 2)]) / 2\n",
        "\n",
        "print('Cleaned mean RT:', round(mean_cleaned, 1), 'ms')\n",
        "print('Cleaned median RT:', median_cleaned, 'ms')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7 â€“ Classify Overall Performance\n",
        "We classify the subjectâ€™s performance based on the average reaction time:\n",
        "\n",
        "| Mean RT (ms) | Performance |\n",
        "|---------------|-------------|\n",
        "| < 280 | Excellent |\n",
        "| 280â€“310 | Average |\n",
        "| > 310 | Needs improvement |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if mean_cleaned < 280:\n",
        "    performance = 'Excellent'\n",
        "elif mean_cleaned <= 310:\n",
        "    performance = 'Average'\n",
        "else:\n",
        "    performance = 'Needs improvement'\n",
        "print('Performance:', performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8 â€“ Print Summary of Results\n",
        "We can now print a full summary of all the key results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Trials analyzed:', len(cleaned_rts))\n",
        "print('Mean RT:', round(mean_cleaned, 1), 'ms')\n",
        "print('Median RT:', median_cleaned, 'ms')\n",
        "print('Fastest RT:', min(cleaned_rts), 'ms')\n",
        "print('Slowest RT:', max(cleaned_rts), 'ms')\n",
        "print('Performance:', performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9 â€“ Store Results in a Dictionary\n",
        "Now that we have all results, we can place them together in a **dictionary**. This lets us keep everything organized in one variable, making it easier to access or print later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = {\n",
        "    'num_trials': len(cleaned_rts),\n",
        "    'mean': round(mean_cleaned, 1),\n",
        "    'median': median_cleaned,\n",
        "    'fastest': min(cleaned_rts),\n",
        "    'slowest': max(cleaned_rts),\n",
        "    'performance': performance\n",
        "}\n",
        "print('Results dictionary:')\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10 â€“ Built-In Functions Teaser\n",
        "Python provides built-in functions that can do these steps instantly, but understanding the manual approach first is valuable. Hereâ€™s how it could look with built-ins:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a563d6dc",
      "metadata": {},
      "source": [
        "## Step 10 â€“ Built-In Functions Teaser\n",
        "All the analysis steps above (counting trials, computing mean and median, finding fastest and slowest) can also be done in one line each using Pythonâ€™s built-in functions.\n",
        "Here, we use the cleaned list of reaction times `cleaned_rts` directly as input.\n",
        "The only step we still do manually is the performance classification, since it depends on our own thresholds and interpretation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statistics\n",
        "\n",
        "print('Trials analyzed:', len(cleaned_rts))\n",
        "print('Mean RT:', round(statistics.mean(cleaned_rts),1), 'ms')\n",
        "print('Median RT:', statistics.median(cleaned_rts), 'ms')\n",
        "print('Fastest RT:', min(cleaned_rts), 'ms')\n",
        "print('Slowest RT:', max(cleaned_rts), 'ms')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§© Bonus 1 â€“ Full Reaction Times (Larger Dataset)\n",
        "We can test if our code still works for larger datasets. The following code generates **1000 trials** with mostly realistic reaction times and a few outliers.\n",
        "\n",
        "Simply overwrite your `reaction_times` list at the top with this new dataset and rerun your analysis. If it runs without errors, your code is general and robust!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "n_trials = 1000             # number of simulated trials\n",
        "random.seed(42)             # ensures reproducibility\n",
        "\n",
        "full_reaction_times = []\n",
        "for i in range(n_trials):\n",
        "    rt = random.gauss(275, 25)         # generate RT around 300 ms\n",
        "    if random.random() < 0.01:         # add ~1% random outliers\n",
        "        rt = random.choice([random.randint(50, 120), random.randint(900, 1200)])\n",
        "    full_reaction_times.append(round(rt, 1))\n",
        "\n",
        "print('Example of first 20 reaction times:')\n",
        "print(full_reaction_times[:20])\n",
        "print('Total trials generated:', len(full_reaction_times))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ Bonus 2 â€“ Sorting Algorithm (Bubble Sort)\n",
        "Finally, we can implement our own sorting algorithm â€” **Bubble Sort**. This algorithm repeatedly compares two neighboring elements and swaps them if they are in the wrong order.\n",
        "\n",
        "Each pass pushes the largest remaining value toward the end of the list, like a bubble rising to the surface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# strictly not the literal bubble sort\n",
        "\n",
        "bubble_sorted = cleaned_rts[:]\n",
        "for i in range(len(bubble_sorted)-1):\n",
        "    for j in range(len(bubble_sorted)-1-i):\n",
        "        if bubble_sorted[j] > bubble_sorted[j+1]:\n",
        "            bubble_sorted[j], bubble_sorted[j+1] = bubble_sorted[j+1], bubble_sorted[j]\n",
        "print('Bubble-sorted RTs:', bubble_sorted)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mne",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
